{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158b808e",
   "metadata": {},
   "source": [
    "# Step : Place Discovery \n",
    "\n",
    "**Purpose:** Discover Google Maps place IDs for business locations across Moroccan cities\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to use the DiscoveryEngine\n",
    "- Multi-strategy search (with map center, without center, local search)\n",
    "- Business-type-specific search queries\n",
    "- Deduplication and canonical place_id resolution\n",
    "- Output formats and data structure\n",
    "\n",
    "**For Junior Developers:**\n",
    "- Each cell is self-contained and can be run independently\n",
    "- Clear outputs show what's happening at each step\n",
    "- Test sections let you experiment safely with small data\n",
    "- Works with any business type (banks, hotels, restaurants, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be01f8",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8bfc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Import our modules\n",
    "from review_analyzer.discover import DiscoveryEngine\n",
    "from review_analyzer import config\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"\\nAvailable map centers: {len(config.DEFAULT_MAP_CENTERS)} cities\")\n",
    "print(f\"Sample cities: {list(config.DEFAULT_MAP_CENTERS.keys())[:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fad7f0",
   "metadata": {},
   "source": [
    "## Data Architecture Overview\n",
    "\n",
    "The pipeline uses an organized folder structure:\n",
    "\n",
    "```\n",
    "data/\n",
    " 00_config/ # Static configurations\n",
    " cities/ # City aliases, coordinates, regions.geojson\n",
    " templates/ # Business templates\n",
    " 0_raw/ # Immutable source data\n",
    " discovery/ # Discovered places (timestamped folders)\n",
    " 0_interim/ # Recomputable cache\n",
    " discovery/ # Discovery cache (place_id_cache.json)\n",
    " 0_processed/ # Final outputs\n",
    " discovery/ # Processed agency lists\n",
    " 0_analysis/ # Reports, figures, dashboards\n",
    " 99_archive/ # Deprecated data\n",
    "\n",
    "logs/ # Pipeline execution logs\n",
    "```\n",
    "\n",
    "**This notebook saves data to:**\n",
    "- `data/0_processed/discovery/` - Final discovered places\n",
    "- `data/0_interim/discovery/cache/` - Place ID resolution cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f676c87",
   "metadata": {},
   "source": [
    "## Test : Initialize Discovery Engine\n",
    "\n",
    "**What this does:** Creates a DiscoveryEngine instance that will handle API calls to Google Maps\n",
    "\n",
    "**Expected output:** Confirmation that engine is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the discovery engine\n",
    "engine = DiscoveryEngine(debug=True)\n",
    "\n",
    "print(\" DiscoveryEngine initialized successfully!\")\n",
    "print(f\" Debug mode: {engine.debug}\")\n",
    "print(f\" Client ready: {engine.client is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibility: add city aliases to DEFAULT_MAP_CENTERS for accented/localized names\n",
    "alias_map = {\n",
    " \"Fès\": \"Fes\",\n",
    " \"Tanger\": \"Tangier\",\n",
    " \"Kénitra\": \"Kenitra\",\n",
    " \"Kenitra\": \"Kenitra\",\n",
    "}\n",
    "for alias, canonical in alias_map.items():\n",
    " if canonical in config.DEFAULT_MAP_CENTERS:\n",
    " config.DEFAULT_MAP_CENTERS[alias] = config.DEFAULT_MAP_CENTERS[canonical]\n",
    "print(\" City aliases added (FèsFes, TangerTangier, KénitraKenitra)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e12259d",
   "metadata": {},
   "source": [
    "## Test : Single Business, Single City (Simplest Case)\n",
    "\n",
    "**What this does:** Discovers locations for ONE business in ONE city\n",
    "\n",
    "**Use case:** Perfect for testing or debugging\n",
    "\n",
    "**Business type parameter:** Helps refine search queries (e.g., \"agence\" for banks, \"hotel\" for hotels)\n",
    "\n",
    "**Expected output:** CSV file with place_ids, addresses, and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa4476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with single business and city (BANK EXAMPLE)\n",
    "test_businesses = [\"CFG Bank\"]\n",
    "test_business_type = \"bank\"\n",
    "test_cities = [\"Casablanca\"]\n",
    "\n",
    "# Output path (use new data architecture)\n",
    "output_path = project_root / \"data\" / \"0_processed\" / \"discovery\" / f\"test_single_discovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Searching for: {test_businesses[0]} ({test_business_type}) in {test_cities[0]}\")\n",
    "print(f\"Output will be saved to: {output_path.name}\\n\")\n",
    "\n",
    "# Run discovery\n",
    "df = engine.discover_branches(\n",
    " businesses=test_businesses,\n",
    " cities=test_cities,\n",
    " business_type=test_business_type,\n",
    " map_centers={\"Casablanca\": config.DEFAULT_MAP_CENTERS[\"Casablanca\"]},\n",
    " brand_filter=\"CFG Bank\",\n",
    " output_path=output_path\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISCOVERY COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\" Total locations found: {len(df)}\")\n",
    "print(f\" Output file: {output_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview results\n",
    "df = pd.read_csv(output_path)\n",
    "\n",
    "print(f\"\\nRESULTS PREVIEW\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"Total places found: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\\n\")\n",
    "\n",
    "# Show first few results\n",
    "print(\"First places:\")\n",
    "display(df.head())\n",
    "\n",
    "# Show summary statistics\n",
    "print(f\"\\nSUMMARY\")\n",
    "print(f\" Unique place_ids: {df['place_id'].nunique()}\")\n",
    "if '_city' in df.columns:\n",
    " print(f\" Cities: {df['_city'].unique().tolist()}\")\n",
    "if '_business' in df.columns:\n",
    " print(f\" Businesses: {df['_business'].unique().tolist()}\")\n",
    "if 'business_type' in df.columns:\n",
    " print(f\" Business types: {df['business_type'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085bb836",
   "metadata": {},
   "source": [
    "## Test : Multiple Businesses, Single City\n",
    "\n",
    "**What this does:** Discovers locations for MULTIPLE businesses in one city\n",
    "\n",
    "**Use case:** Competitive analysis in a specific market (e.g., comparing banks in Rabat)\n",
    "\n",
    "**Expected output:** Combined results for all businesses with comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf562248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple businesses, one city (BANK EXAMPLE)\n",
    "test_businesses = [\n",
    " \"Attijariwafa Bank\",\n",
    " \"BMCE Bank\",\n",
    " \"CIH Bank\"\n",
    "]\n",
    "test_business_type = \"bank\"\n",
    "test_cities = [\"Rabat\"]\n",
    "\n",
    "output_path = project_root / \"data\" / \"0_processed\" / \"discovery\" / f\"test_multi_business_discovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Searching for {len(test_businesses)} {test_business_type}s in {test_cities[0]}:\")\n",
    "for business in test_businesses:\n",
    " print(f\" - {business}\")\n",
    "print(f\"\\nOutput: {output_path.name}\\n\")\n",
    "\n",
    "# Run discovery\n",
    "df = engine.discover_branches(\n",
    " businesses=test_businesses,\n",
    " cities=test_cities,\n",
    " business_type=test_business_type,\n",
    " map_centers={\"Rabat\": config.DEFAULT_MAP_CENTERS[\"Rabat\"]},\n",
    " brand_filter=None, # No filtering to get all results\n",
    " output_path=output_path\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" DISCOVERY COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\" Total locations: {len(df)}\")\n",
    "if '_business' in df.columns:\n",
    " print(f\"\\n Breakdown by business:\")\n",
    " for business in test_businesses:\n",
    " count = len(df[df['_business'] == business])\n",
    " print(f\" {business}: {count} locations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff60c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze results by business\n",
    "df = pd.read_csv(output_path)\n",
    "\n",
    "print(f\"\\n RESULTS BY BUSINESS\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "if '_business' in df.columns:\n",
    " business_counts = df.groupby('_business').size().sort_values(ascending=False)\n",
    " print(\"\\nLocations per business:\")\n",
    " for business, count in business_counts.items():\n",
    " print(f\" {business}: {count} locations\")\n",
    " \n",
    " # Show sample from each business\n",
    " print(f\"\\n Sample from each business:\")\n",
    " for business in business_counts.index:\n",
    " business_data = df[df['_business'] == business].head()\n",
    " print(f\"\\n{business}:\")\n",
    " display(business_data[['_place_id', 'name', 'address']].head())\n",
    "else:\n",
    " print(\"\\nAll results:\")\n",
    " display(df.head(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3abe2c",
   "metadata": {},
   "source": [
    "## Test : Different Business Types \n",
    "\n",
    "**What this does:** Shows how to discover different types of businesses (hotels, restaurants, etc.)\n",
    "\n",
    "**Use case:** Demonstrates the flexibility of the new business-type-aware system\n",
    "\n",
    "**Expected output:** Examples with hotels and restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93fed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE : Hotels in Marrakech\n",
    "print(\" DISCOVERING HOTELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_businesses = [\"Hilton\", \"Marriott\"]\n",
    "test_business_type = \"hotel\"\n",
    "test_cities = [\"Marrakech\"]\n",
    "\n",
    "output_path = project_root / \"data\" / \"0_processed\" / \"discovery\" / f\"test_hotels_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\" Searching for hotels in {test_cities[0]}:\")\n",
    "for business in test_businesses:\n",
    " print(f\" - {business}\")\n",
    "\n",
    "# Run discovery\n",
    "df_hotels = engine.discover_branches(\n",
    " businesses=test_businesses,\n",
    " cities=test_cities,\n",
    " business_type=test_business_type,\n",
    " map_centers={\"Marrakech\": config.DEFAULT_MAP_CENTERS[\"Marrakech\"]},\n",
    " output_path=output_path\n",
    ")\n",
    "\n",
    "print(f\"\\n Found {len(df_hotels)} hotel locations\")\n",
    "if '_business' in df_hotels.columns:\n",
    " for business in test_businesses:\n",
    " count = len(df_hotels[df_hotels['_business'] == business])\n",
    " print(f\" {business}: {count} locations\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample results:\")\n",
    "display(df_hotels[['business', 'name', 'address', 'lat', 'lng', 'place_id','rating', 'reviews_count']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_hotels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee92df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE : Restaurants in Casablanca\n",
    "print(\"DISCOVERING RESTAURANTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_businesses = [\"McDonald's\", \"KFC\"]\n",
    "test_business_type = \"restaurant\"\n",
    "test_cities = [\"Casablanca\"]\n",
    "\n",
    "output_path = project_root / \"data\" / \"0_processed\" / \"discovery\" / f\"test_restaurants_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Searching for restaurants in {test_cities[0]}:\")\n",
    "for business in test_businesses:\n",
    " print(f\" - {business}\")\n",
    "\n",
    "# Run discovery\n",
    "df_restaurants = engine.discover_branches(\n",
    " businesses=test_businesses,\n",
    " cities=test_cities,\n",
    " business_type=test_business_type,\n",
    " map_centers={\"Casablanca\": config.DEFAULT_MAP_CENTERS[\"Casablanca\"]},\n",
    " output_path=output_path\n",
    ")\n",
    "\n",
    "print(f\"\\nFound {len(df_restaurants)} restaurant locations\")\n",
    "if '_business' in df_restaurants.columns:\n",
    " for business in test_businesses:\n",
    " count = len(df_restaurants[df_restaurants['_business'] == business])\n",
    " print(f\" {business}: {count} locations\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample results:\")\n",
    "display(df_restaurants[['business', 'name', 'address', 'lat', 'lng', 'place_id','rating', 'reviews_count']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a42ad40",
   "metadata": {},
   "source": [
    "## Test : Single Business, Multiple Cities\n",
    "\n",
    "**What this does:** Discovers locations for one business across MULTIPLE cities\n",
    "\n",
    "**Use case:** Mapping a business's geographic coverage\n",
    "\n",
    "**Expected output:** Location distribution across cities with geographic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ccd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with single business, multiple cities (BANK EXAMPLE)\n",
    "test_businesses = [\"Banque Populaire\"]\n",
    "test_business_type = \"bank\"\n",
    "test_cities = [\n",
    " \"Casablanca\",\n",
    " \"Rabat\",\n",
    " \"Marrakech\",\n",
    " \"Fès\"\n",
    "]\n",
    "\n",
    "# Get map centers for selected cities\n",
    "map_centers = {city: config.DEFAULT_MAP_CENTERS[city] for city in test_cities}\n",
    "\n",
    "output_path = project_root / \"data\" / \"0_processed\" / \"discovery\" / f\"test_multi_city_discovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Searching for {test_businesses[0]} in {len(test_cities)} cities:\")\n",
    "for city in test_cities:\n",
    " print(f\" - {city}\")\n",
    "print(f\"\\nOutput: {output_path.name}\\n\")\n",
    "\n",
    "# Run discovery\n",
    "df = engine.discover_branches(\n",
    " businesses=test_businesses,\n",
    " cities=test_cities,\n",
    " business_type=test_business_type,\n",
    " map_centers=map_centers,\n",
    " brand_filter=\"Banque Populaire\",\n",
    " output_path=output_path\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISCOVERY COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\" Total locations: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37baa1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze geographic distribution\n",
    "df = pd.read_csv(output_path)\n",
    "\n",
    "print(f\"\\nGEOGRAPHIC DISTRIBUTION\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "if '_city' in df.columns:\n",
    " city_counts = df.groupby('_city').size().sort_values(ascending=False)\n",
    " print(\"\\nLocations per city:\")\n",
    " for city, count in city_counts.items():\n",
    " percentage = (count / len(df)) * 00\n",
    " bar = '' * int(percentage / )\n",
    " print(f\" {city:} {count:} locations {bar} {percentage:.f}%\")\n",
    " \n",
    " # Show sample from each city\n",
    " print(f\"\\nSample locations from each city:\")\n",
    " for city in city_counts.index:\n",
    " city_data = df[df['_city'] == city].head()\n",
    " print(f\"\\n{city}:\")\n",
    " display(city_data[['_place_id', 'name', 'address']].head())\n",
    "else:\n",
    " print(\"\\nAll results:\")\n",
    " display(df.head(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a755ee73",
   "metadata": {},
   "source": [
    "## Test 6: Full Production Run (Multiple Businesses × Multiple Cities)\n",
    "\n",
    "**What this does:** Production-scale discovery across all major businesses and cities\n",
    "\n",
    "**Use case:** Complete market mapping (can be used for any business type)\n",
    "\n",
    "**Warning:** This makes many API calls and may take several minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production configuration (BANK EXAMPLE)\n",
    "production_businesses = [\n",
    " \"Attijariwafa Bank\",\n",
    " \"BMCE Bank\",\n",
    " \"CIH Bank\",\n",
    " \"Banque Populaire\",\n",
    " \"Société Générale Maroc\"\n",
    "]\n",
    "\n",
    "production_business_type = \"bank\"\n",
    "\n",
    "production_cities = [\n",
    " \"Casablanca\",\n",
    " \"Rabat\",\n",
    " \"Marrakech\",\n",
    " \"Fès\",\n",
    " \"Tanger\",\n",
    " \"Agadir\"\n",
    "]\n",
    "\n",
    "# Get map centers\n",
    "map_centers = {city: config.DEFAULT_MAP_CENTERS[city] for city in production_cities if city in config.DEFAULT_MAP_CENTERS}\n",
    "\n",
    "output_path = project_root / \"data\" / \"0_processed\" / \"discovery\" / f\"production_discovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"PRODUCTION RUN\")\n",
    "print(f\"=\"*60)\n",
    "print(f\" Businesses: {len(production_businesses)}\")\n",
    "print(f\" Cities: {len(production_cities)}\")\n",
    "print(f\" Total combinations: {len(production_businesses) * len(production_cities)}\")\n",
    "print(f\"\\n This will take several minutes...\\n\")\n",
    "print(f\"Output: {output_path.name}\\n\")\n",
    "\n",
    "# Uncomment to run\n",
    "# df = engine.discover_branches(\n",
    "# businesses=production_businesses,\n",
    "# cities=production_cities,\n",
    "# business_type=production_business_type,\n",
    "# map_centers=map_centers,\n",
    "# brand_filter=None,\n",
    "# output_path=output_path\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133053ab",
   "metadata": {},
   "source": [
    "## Test 6: Inspect and Validate Results\n",
    "\n",
    "**What this does:** Quality checks on discovered data\n",
    "\n",
    "**Checks:**\n",
    "- Duplicate place_ids\n",
    "- Missing data\n",
    "- Place_id format validation\n",
    "- Data completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be190660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load most recent discovery file (check new data architecture first)\n",
    "output_dir = project_root / \"data\" / \"0_processed\" / \"discovery\"\n",
    "if not output_dir.exists():\n",
    " output_dir = project_root / \"data\" / \"output\" # Fallback to legacy\n",
    "\n",
    "discovery_files = sorted(output_dir.glob(\"*discovery*.csv\"), reverse=True)\n",
    "\n",
    "if discovery_files:\n",
    " latest_file = discovery_files[0]\n",
    " print(f\"Loading: {latest_file.name}\\n\")\n",
    " \n",
    " df = pd.read_csv(latest_file)\n",
    " \n",
    " print(f\"DATA QUALITY CHECKS\")\n",
    " print(f\"=\"*60)\n",
    " \n",
    " # Choose best ID column\n",
    " id_col = (\n",
    " 'canonical_place_id'\n",
    " if ('canonical_place_id' in df.columns and df['canonical_place_id'].notna().any())\n",
    " else 'place_id' if 'place_id' in df.columns else None\n",
    " )\n",
    " \n",
    " # . Check for duplicates\n",
    " print(f\"\\n. Duplicate Check:\")\n",
    " if id_col:\n",
    " duplicates = df[id_col].duplicated().sum()\n",
    " if duplicates > 0:\n",
    " print(f\"Found {duplicates} duplicate place_ids\")\n",
    " print(f\" Duplicated IDs: {df[df[id_col].duplicated()][id_col].tolist()}\")\n",
    " else:\n",
    " print(f\"No duplicates found\")\n",
    " else:\n",
    " print(f\"No ID column available\")\n",
    " \n",
    " # . Check for missing data\n",
    " print(f\"\\n. Missing Data Check:\")\n",
    " missing = df.isnull().sum()\n",
    " if missing.sum() > 0:\n",
    " print(f\" Columns with missing values:\")\n",
    " for col, count in missing[missing > 0].items():\n",
    " print(f\" {col}: {count} missing ({count/len(df)*00:.f}%)\")\n",
    " else:\n",
    " print(f\" No missing data\")\n",
    " \n",
    " # . Validate place_id format\n",
    " print(f\"\\n. Place ID Format Check:\")\n",
    " if id_col:\n",
    " non_null_ids = df[id_col].dropna()\n",
    " invalid_ids = non_null_ids[~non_null_ids.astype(str).apply(config.validate_place_id)]\n",
    " if len(invalid_ids) > 0:\n",
    " print(f\"Found {len(invalid_ids)} invalid place_ids\")\n",
    " print(f\" Invalid IDs: {invalid_ids.astype(str).tolist()[:]}\")\n",
    " else:\n",
    " print(f\"All place_ids valid (ChIJ format)\")\n",
    " else:\n",
    " print(f\"Skipped: no ID column found\")\n",
    " \n",
    " # . Data completeness\n",
    " print(f\"\\n. Data Completeness:\")\n",
    " print(f\" Total records: {len(df)}\")\n",
    " if id_col:\n",
    " print(f\" Unique place_ids: {df[id_col].nunique()}\")\n",
    " \n",
    " # Support both old and new column names\n",
    " business_col = 'business' if 'business' in df.columns else '_business' if '_business' in df.columns else None\n",
    " city_col = 'city' if 'city' in df.columns else '_city' if '_city' in df.columns else None\n",
    " \n",
    " if business_col:\n",
    " businesses = df[business_col].dropna().unique()\n",
    " print(f\" Businesses: {len(businesses)} ({', '.join(businesses[:])})\")\n",
    " if city_col:\n",
    " cities = df[city_col].dropna().unique()\n",
    " print(f\" Cities: {len(cities)} ({', '.join(cities[:])})\")\n",
    " \n",
    " # . Show sample\n",
    " print(f\"\\n. Sample Records:\")\n",
    " display(df.head())\n",
    " \n",
    "else:\n",
    " print(\"No discovery files found. Run a test first!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55333da",
   "metadata": {},
   "source": [
    "## Test 7: Visualize Discovery Results\n",
    "\n",
    "**What this does:** Create visualizations of discovered branches\n",
    "\n",
    "**Outputs:**\n",
    "- Bar chart: Branches per city\n",
    "- Bar chart: Branches per bank\n",
    "- Heatmap: Bank coverage by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fede6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load latest discovery file\n",
    "if discovery_files:\n",
    " df = pd.read_csv(discovery_files[0])\n",
    " \n",
    " print(f\"VISUALIZATIONS\")\n",
    " print(f\"=\"*60)\n",
    " print(f\"\\nData: {discovery_files[0].name}\")\n",
    " print(f\"Total branches: {len(df)}\\n\")\n",
    " \n",
    " # Support both old and new column names\n",
    " city_col = 'city' if 'city' in df.columns else '_city' if '_city' in df.columns else None\n",
    " business_col = 'business' if 'business' in df.columns else '_business' if '_business' in df.columns else '_bank' if '_bank' in df.columns else None\n",
    " \n",
    " # . Branches per city\n",
    " if city_col and city_col in df.columns:\n",
    " fig, ax = plt.subplots(figsize=(0, 6))\n",
    " city_counts = df[city_col].value_counts()\n",
    " city_counts.plot(kind='bar', ax=ax, color='steelblue')\n",
    " ax.set_title('Branches per City', fontsize=, fontweight='bold')\n",
    " ax.set_xlabel('City', fontsize=)\n",
    " ax.set_ylabel('Number of Branches', fontsize=)\n",
    " ax.grid(axis='y', alpha=0.)\n",
    " plt.xticks(rotation=, ha='right')\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " # . Branches per business\n",
    " if business_col and business_col in df.columns:\n",
    " fig, ax = plt.subplots(figsize=(0, 6))\n",
    " business_counts = df[business_col].value_counts()\n",
    " business_counts.plot(kind='barh', ax=ax, color='coral')\n",
    " ax.set_title('Branches per Business', fontsize=, fontweight='bold')\n",
    " ax.set_xlabel('Number of Branches', fontsize=)\n",
    " ax.set_ylabel('Business', fontsize=)\n",
    " ax.grid(axis='x', alpha=0.)\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " # . Heatmap: Business × City coverage\n",
    " if business_col and city_col and business_col in df.columns and city_col in df.columns:\n",
    " coverage = pd.crosstab(df[business_col], df[city_col])\n",
    " fig, ax = plt.subplots(figsize=(, 6))\n",
    " sns.heatmap(coverage, annot=True, fmt='d', cmap='YlOrRd', ax=ax)\n",
    " ax.set_title('Business Coverage by City (Number of Branches)', fontsize=, fontweight='bold')\n",
    " ax.set_xlabel('City', fontsize=)\n",
    " ax.set_ylabel('Business', fontsize=)\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " print(\"\\nCoverage Matrix:\")\n",
    " display(coverage)\n",
    "else:\n",
    " print(\"No discovery files found. Run a test first!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29023aed",
   "metadata": {},
   "source": [
    "## Export for Next Step\n",
    "\n",
    "**What this does:** Prepares discovery results for Step (Review Collection)\n",
    "\n",
    "**Output:** Clean CSV file ready for the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edeba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for next step\n",
    "if discovery_files:\n",
    " df = pd.read_csv(discovery_files[-])\n",
    " \n",
    " # Clean and prepare\n",
    " required_columns = ['_place_id', '_bank', '_city', 'title', 'address']\n",
    " available_columns = [col for col in required_columns if col in df.columns]\n",
    " \n",
    " df_clean = df[available_columns].drop_duplicates(subset=['_place_id'])\n",
    " \n",
    " # Save for next step\n",
    " next_step_file = project_root / \"data\" / \"output\" / \"agencies_for_collection.csv\"\n",
    " df_clean.to_csv(next_step_file, index=False)\n",
    " \n",
    " print(f\"EXPORT COMPLETE\")\n",
    " print(f\"=\"*60)\n",
    " print(f\" File: {next_step_file.name}\")\n",
    " print(f\" Records: {len(df_clean)}\")\n",
    " print(f\" Columns: {list(df_clean.columns)}\")\n",
    " print(f\"\\n Ready for Step : Review Collection! \")\n",
    " print(f\" Open: collect_reviews.ipynb\")\n",
    "else:\n",
    " print(\"No discovery files found. Run a test first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED: Load and preview results (aligns with new discover.py schema)\n",
    "\n",
    "df = pd.read_csv(output_path)\n",
    "\n",
    "print(\"\\nRESULTS PREVIEW (updated)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total places found: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\\n\")\n",
    "\n",
    "# Show first few results with key columns when available\n",
    "print(\"First places:\")\n",
    "key_cols = [c for c in [\n",
    " 'business', 'name', 'address', 'city', 'place_id',\n",
    " 'canonical_place_id', 'data_id', 'rating', 'reviews_count',\n",
    " '_engine', 'resolve_status'\n",
    "] if c in df.columns]\n",
    "\n",
    "display(df[key_cols].head() if key_cols else df.head())\n",
    "\n",
    "# Summary (prefer canonical ids when present)\n",
    "id_col = (\n",
    " 'canonical_place_id'\n",
    " if ('canonical_place_id' in df.columns and df['canonical_place_id'].notna().any())\n",
    " else 'place_id' if 'place_id' in df.columns else None\n",
    ")\n",
    "\n",
    "print(\"\\nSUMMARY (updated)\")\n",
    "if id_col:\n",
    " print(f\" Unique IDs ({id_col}): {df[id_col].nunique()}\")\n",
    "else:\n",
    " print(\" Unique IDs: N/A\")\n",
    "\n",
    "if 'city' in df.columns:\n",
    " print(f\" Cities: {df['city'].unique().tolist()}\")\n",
    "if 'business' in df.columns:\n",
    " print(f\" Businesses: {df['business'].unique().tolist()}\")\n",
    "if 'business_type' in df.columns:\n",
    " print(f\" Business types: {df['business_type'].unique().tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b18034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED: Analyze results by business (aligns with new columns)\n",
    "\n",
    "df = pd.read_csv(output_path)\n",
    "\n",
    "print(\"\\nRESULTS BY BUSINESS (updated)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "group_col = 'business' if 'business' in df.columns else None\n",
    "id_col = (\n",
    " 'canonical_place_id'\n",
    " if ('canonical_place_id' in df.columns and df['canonical_place_id'].notna().any())\n",
    " else 'place_id' if 'place_id' in df.columns else None\n",
    ")\n",
    "\n",
    "if group_col:\n",
    " business_counts = df.groupby(group_col).size().sort_values(ascending=False)\n",
    " print(\"\\nLocations per business:\")\n",
    " for business, count in business_counts.items():\n",
    " print(f\" {business}: {count} locations\")\n",
    " \n",
    " print(\"\\nSample from each business:\")\n",
    " for business_name in business_counts.index:\n",
    " sample = df[df[group_col] == business_name].head()\n",
    " cols = [c for c in [id_col, 'name', 'address'] if c in df.columns and id_col]\n",
    " display(sample[cols] if cols else sample.head())\n",
    "else:\n",
    " print(\"\\nAll results:\")\n",
    " display(df.head(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED: Inspect and validate results (new schema + tolerant to unresolved IDs)\n",
    "\n",
    "# Load most recent discovery file in output directory\n",
    "output_dir = project_root / \"data\" / \"output\"\n",
    "discovery_files = sorted(output_dir.glob(\"*discovery*.csv\"))\n",
    "\n",
    "if discovery_files:\n",
    " latest_file = discovery_files[-]\n",
    " print(f\"Loading: {latest_file.name}\\n\")\n",
    " \n",
    " df = pd.read_csv(latest_file)\n",
    " \n",
    " print(\"DATA QUALITY CHECKS (updated)\")\n",
    " print(\"=\"*60)\n",
    " \n",
    " # Choose best id column available\n",
    " id_col = (\n",
    " 'canonical_place_id'\n",
    " if ('canonical_place_id' in df.columns and df['canonical_place_id'].notna().any())\n",
    " else 'place_id' if 'place_id' in df.columns else None\n",
    " )\n",
    " \n",
    " # . Check for duplicates\n",
    " print(\"\\n. Duplicate Check:\")\n",
    " if id_col:\n",
    " duplicates = df[id_col].duplicated().sum()\n",
    " print(f\" Duplicates in {id_col}: {duplicates}\")\n",
    " else:\n",
    " print(\" No ID column available for duplicate check\")\n",
    " \n",
    " # . Missing Data Check\n",
    " print(\"\\n. Missing Data Check:\")\n",
    " missing = df.isnull().sum()\n",
    " if missing.sum() > 0:\n",
    " print(\" Columns with missing values:\")\n",
    " for col, count in missing[missing > 0].items():\n",
    " print(f\" {col}: {count} missing ({count/len(df)*00:.f}%)\")\n",
    " else:\n",
    " print(\"No missing data\")\n",
    " \n",
    " # . Place ID Format Check (canonical format only)\n",
    " print(\"\\n. Place ID Format Check:\")\n",
    " if id_col:\n",
    " non_null_ids = df[id_col].dropna()\n",
    " invalid_ids = non_null_ids[~non_null_ids.astype(str).apply(config.validate_place_id)]\n",
    " if len(invalid_ids) > 0:\n",
    " print(f\"Found {len(invalid_ids)} invalid IDs in {id_col}\")\n",
    " print(f\"Sample invalid: {invalid_ids.astype(str).tolist()[:]}\")\n",
    " else:\n",
    " print(f\"All non-null IDs in {id_col} match canonical format (ChIJ...)\")\n",
    " else:\n",
    " print(\" Skipped: no ID column found\")\n",
    " \n",
    " # . Data completeness\n",
    " print(\"\\n. Data Completeness:\")\n",
    " print(f\" Total records: {len(df)}\")\n",
    " if id_col:\n",
    " print(f\" Unique IDs: {df[id_col].nunique()}\")\n",
    " if 'business' in df.columns:\n",
    " print(f\" Businesses: {df['business'].nunique()} ({', '.join(df['business'].dropna().unique()[:0])}...) \")\n",
    " if 'city' in df.columns:\n",
    " print(f\" Cities: {df['city'].nunique()} ({', '.join(df['city'].dropna().unique()[:0])}...) \")\n",
    " \n",
    " # . Show sample\n",
    " print(\"\\n. Sample Records:\")\n",
    " sample_cols = [c for c in [id_col, 'business', 'city', 'name', 'address'] if c and c in df.columns]\n",
    " display(df[sample_cols].head() if sample_cols else df.head())\n",
    "else:\n",
    " print(\"No discovery files found. Run a test first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED: Visualize discovery results (city/business columns)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load latest discovery file\n",
    "if discovery_files:\n",
    " df = pd.read_csv(discovery_files[-])\n",
    " \n",
    " print(\"VISUALIZATIONS (updated)\")\n",
    " print(\"=\"*60)\n",
    " print(f\"\\nData: {discovery_files[-].name}\")\n",
    " print(f\"Total branches: {len(df)}\\n\")\n",
    " \n",
    " # . Branches per city\n",
    " if 'city' in df.columns and not df['city'].isna().all():\n",
    " fig, ax = plt.subplots(figsize=(0, 6))\n",
    " city_counts = df['city'].value_counts()\n",
    " city_counts.plot(kind='bar', ax=ax, color='steelblue')\n",
    " ax.set_title('Branches per City', fontsize=, fontweight='bold')\n",
    " ax.set_xlabel('City', fontsize=)\n",
    " ax.set_ylabel('Number of Branches', fontsize=)\n",
    " ax.grid(axis='y', alpha=0.)\n",
    " plt.xticks(rotation=, ha='right')\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " # . Branches per business\n",
    " if 'business' in df.columns and not df['business'].isna().all():\n",
    " fig, ax = plt.subplots(figsize=(0, 6))\n",
    " business_counts = df['business'].value_counts()\n",
    " business_counts.plot(kind='barh', ax=ax, color='coral')\n",
    " ax.set_title('Branches per Business', fontsize=, fontweight='bold')\n",
    " ax.set_xlabel('Number of Branches', fontsize=)\n",
    " ax.set_ylabel('Business', fontsize=)\n",
    " ax.grid(axis='x', alpha=0.)\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " # . Heatmap: Business × City coverage\n",
    " if 'business' in df.columns and 'city' in df.columns:\n",
    " coverage = pd.crosstab(df['business'], df['city'])\n",
    " fig, ax = plt.subplots(figsize=(, 6))\n",
    " sns.heatmap(coverage, annot=True, fmt='d', cmap='YlOrRd', ax=ax)\n",
    " ax.set_title('Business Coverage by City (Number of Branches)', fontsize=, fontweight='bold')\n",
    " ax.set_xlabel('City', fontsize=)\n",
    " ax.set_ylabel('Business', fontsize=)\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " print(\"\\nCoverage Matrix:\")\n",
    " display(coverage)\n",
    "else:\n",
    " print(\"No discovery files found. Run a test first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for next step (transform or collection)\n",
    "if discovery_files:\n",
    " df = pd.read_csv(discovery_files[0])\n",
    " \n",
    " # Choose best id per row: canonical_place_id > place_id > data_id (as string)\n",
    " def choose_id(row):\n",
    " cid = row.get('canonical_place_id')\n",
    " if isinstance(cid, str) and config.validate_place_id(cid):\n",
    " return cid\n",
    " pid = row.get('place_id')\n",
    " if isinstance(pid, str) and config.validate_place_id(pid):\n",
    " return pid\n",
    " did = row.get('data_id')\n",
    " if pd.notna(did) and str(did).strip() != \"\":\n",
    " return str(did)\n",
    " return None\n",
    " \n",
    " ids = df.apply(choose_id, axis=)\n",
    " \n",
    " # Support both old and new column names\n",
    " business_col = 'business' if 'business' in df.columns else '_business' if '_business' in df.columns else None\n",
    " city_col = 'city' if 'city' in df.columns else '_city' if '_city' in df.columns else None\n",
    " \n",
    " df_out = pd.DataFrame({\n",
    " '_place_id': ids,\n",
    " '_business': df[business_col] if business_col else '',\n",
    " '_city': df[city_col] if city_col else '',\n",
    " 'title': df.get('name'),\n",
    " 'address': df.get('address')\n",
    " })\n",
    " \n",
    " df_out = df_out.dropna(subset=['_place_id']).drop_duplicates(subset=['_place_id'])\n",
    " \n",
    " # Save to new data architecture\n",
    " next_step_file = project_root / 'data' / '0_processed' / 'discovery' / 'agencies_discovered.csv'\n",
    " next_step_file.parent.mkdir(parents=True, exist_ok=True)\n",
    " df_out.to_csv(next_step_file, index=False)\n",
    " \n",
    " # Also save to legacy path for backward compatibility\n",
    " legacy_file = project_root / 'data' / 'output' / 'agencies_for_collection.csv'\n",
    " legacy_file.parent.mkdir(parents=True, exist_ok=True)\n",
    " df_out.to_csv(legacy_file, index=False)\n",
    " \n",
    " print(\"EXPORT COMPLETE\")\n",
    " print(\"=\"*60)\n",
    " print(f\" Primary: {next_step_file.relative_to(project_root)}\")\n",
    " print(f\" Legacy: {legacy_file.relative_to(project_root)}\")\n",
    " print(f\" Records: {len(df_out)}\")\n",
    " print(f\" Columns: {list(df_out.columns)}\")\n",
    " print(\"\\nData saved to: data/0_processed/discovery/\")\n",
    " print(\"\\nNext steps:\")\n",
    " print(\" .Collect reviews for discovered places\")\n",
    " print(\" Open: collect_reviews.ipynb\")\n",
    " print(\" . Or run full pipeline:\")\n",
    " print(\" python -m review_analyzer.main pipeline --businesses 'Bank' --cities 'City'\")\n",
    "else:\n",
    " print(\"No discovery files found. Run a test first!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2b13f5",
   "metadata": {},
   "source": [
    "## Summary for New Developers\n",
    "\n",
    "**What you learned:**\n",
    "\n",
    ". **DiscoveryEngine** - The main class for finding business locations on Google Maps\n",
    ". **Multi-strategy search** - Uses approaches: map center, no center, local search\n",
    ". **Canonical place IDs** - Automatic resolution to ChIJ format for reliable reviews\n",
    ". **Deduplication** - Automatically removes duplicate place_ids\n",
    ". **Business-type awareness** - Tailored queries for banks, hotels, restaurants, etc.\n",
    "6. **Brand filtering** - Optional filtering by business name\n",
    "7. **Data validation** - How to check data quality\n",
    "8. **New data architecture** - Organized folder structure for better data management\n",
    "\n",
    "**Key takeaways:**\n",
    "- Start with small tests ( business, city)\n",
    "- Scale up gradually\n",
    "- Always validate results\n",
    "- Visualize data to understand coverage\n",
    "- Data is saved to `data/0_processed/discovery/` for next pipeline stage\n",
    "- Cache is maintained in `data/0_interim/discovery/cache/` for efficiency\n",
    "\n",
    "**Data Flow (New Architecture):**\n",
    "```\n",
    "discover collect transform classify\n",
    " ↓ ↓ ↓ ↓\n",
    "0_raw/ 0_interim/ 0_interim/ 0_processed/\n",
    "discovery collection transform classification\n",
    "```\n",
    "\n",
    "**Next steps:**\n",
    ". You've discovered place_ids (Step : discover_placeids.ipynb - this notebook!)\n",
    ". Collect reviews for discovered places (Step : collect_reviews.ipynb)\n",
    ". Transform reviews - normalize fields, add regions (CLI: `python -m review_analyzer.main transform`)\n",
    ". Classify reviews to extract topics and sentiments (Step : classify_reviews.ipynb)\n",
    "\n",
    "**Pipeline Command (Run all steps):**\n",
    "```bash\n",
    "python -m review_analyzer.main pipeline \\\n",
    " --businesses \"Attijariwafa Bank\" \\\n",
    " --cities \"Casablanca\" \\\n",
    " --business-type \"bank\"\n",
    "```\n",
    "\n",
    "**Troubleshooting:**\n",
    "- No results? Check business name spelling matches Google Maps\n",
    "- API errors? Check .env file has SERPAPI_API_KEY set\n",
    "- Duplicates? The engine should handle them automatically\n",
    "- Missing canonical IDs? Engine resolves them via place details API\n",
    "\n",
    "Happy discovering! \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}