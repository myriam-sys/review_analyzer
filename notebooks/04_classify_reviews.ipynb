{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step : Review Classification - Tutorial\n",
    "\n",
    "**Purpose:** Classify reviews using OpenAI GPT- into 7 predefined categories\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to use the ReviewClassifier\n",
    "- Single review vs batch classification\n",
    "- Wide format conversion (7 category columns)\n",
    "- Confidence threshold filtering\n",
    "- Sentiment analysis results\n",
    "\n",
    "**For Junior Developers:**\n",
    "- Clear examples of API usage\n",
    "- Visual outputs showing classification results\n",
    "- Performance monitoring and progress tracking\n",
    "- Error handling demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's New: Enhanced Classification Logic\n",
    "\n",
    "This notebook now uses **proven classification logic from the Scripts folder**:\n",
    "\n",
    "### Scripts Folder Integration:\n",
    "- **Enhanced System Prompt**: Detailed rules, abstention policy, constraints\n",
    "- **Few-Shot Learning**: representative examples included in every API call\n",
    "- **Threshold Filtering**: Removes predictions below {config.CONF_THRESHOLD} confidence\n",
    "- **Fallback Mechanism**: Assigns \"Autre (positif/négatif)\" when no categories pass threshold\n",
    "- **Temperature=0**: Deterministic output (same input same result)\n",
    "- **Robust Extraction**: fallback methods to parse OpenAI responses\n",
    "\n",
    "### Input Compatibility:\n",
    "Auto-detects column names from both:\n",
    "- **New format** (enhanced collection): `text`, `rating`, `_place_id`, `_city`, `_business`\n",
    "- **Old format** (legacy): `review_snippet`, `review_rating`, `_bank`\n",
    "\n",
    "### Key Benefits:\n",
    "- More accurate classifications (few-shot learning improves edge cases)\n",
    "- No empty results (fallback ensures every review gets classified)\n",
    "- Reproducible output (temperature=0)\n",
    "- Backward compatible (works with old data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "print(f\" Project root: {project_root}\")\n",
    "print(f\" Python path updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Import our modules (with reload to pick up latest changes)\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Remove cached modules to force fresh import\n",
    "if 'review_analyzer.config' in sys.modules:\n",
    " del sys.modules['review_analyzer.config']\n",
    "if 'review_analyzer.classify' in sys.modules:\n",
    " del sys.modules['review_analyzer.classify']\n",
    "if 'review_analyzer' in sys.modules:\n",
    " del sys.modules['review_analyzer']\n",
    "\n",
    "from review_analyzer.classify import ReviewClassifier\n",
    "from review_analyzer import config\n",
    "\n",
    "print(\" All imports successful!\")\n",
    "print(f\"\\nAvailable categories: {len(config.CATEGORIES)}\")\n",
    "print(f\"Confidence threshold: {config.CONF_THRESHOLD}\")\n",
    "print(f\"\\n Classification uses:\")\n",
    "print(f\" - Few-shot learning ( examples)\")\n",
    "print(f\" - Threshold filtering ({config.CONF_THRESHOLD})\")\n",
    "print(f\" - Fallback to 'Autre (±)' when needed\")\n",
    "print(f\" - Temperature=0 (deterministic)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Architecture Overview\n",
    "\n",
    "The pipeline uses an organized folder structure:\n",
    "\n",
    "```\n",
    "data/\n",
    " 00_config/ # Static configurations\n",
    " cities/ # City aliases, coordinates, regions.geojson\n",
    " templates/ # Business templates\n",
    " 0_raw/ # Immutable source data\n",
    " 0_interim/ # Recomputable cache\n",
    " collection/ # Collected reviews (input for transform)\n",
    " transform/ # Normalized reviews (input for classification)\n",
    " 0_processed/ # Final outputs\n",
    " classification/ # Classified reviews (this notebook's output)\n",
    " 0_analysis/ # Reports, figures, dashboards\n",
    " 99_archive/ # Deprecated data\n",
    "\n",
    "logs/ # Pipeline execution logs\n",
    "```\n",
    "\n",
    "**This notebook processes:**\n",
    "- Input: `data/0_interim/transform/reviews_normalized.parquet` (after transform step)\n",
    "- Or fallback: `data/0_interim/collection/reviews.csv` (if transform skipped)\n",
    "- Output: `data/0_processed/classification/reviews_classified.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test : View Categories\n",
    "\n",
    "**What this does:** Shows all 7 review categories\n",
    "\n",
    "**Purpose:** Understand what aspects of service are being classified\n",
    "\n",
    "**Note:** Categories are now organized with embedded descriptions (Scripts folder logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all categories\n",
    "print(f\" REVIEW CLASSIFICATION CATEGORIES\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"Total categories: {len(config.CATEGORIES)}\\n\")\n",
    "\n",
    "# Categories are now strings with embedded sentiment indicators\n",
    "# Group by detecting keywords in category labels\n",
    "positive_cats = []\n",
    "negative_cats = []\n",
    "neutral_cats = []\n",
    "autre_cats = []\n",
    "\n",
    "for cat in config.CATEGORIES:\n",
    " cat_lower = cat.lower()\n",
    " if 'autre' in cat_lower:\n",
    " autre_cats.append(cat)\n",
    " elif 'hors-sujet' in cat_lower:\n",
    " neutral_cats.append(cat)\n",
    " elif any(neg_word in cat_lower for neg_word in ['attente', 'lenteur', 'injoignable', 'réclamation', 'incident', 'frais', 'insatisfaction', 'manque']):\n",
    " negative_cats.append(cat)\n",
    " else:\n",
    " # Assume positive if not explicitly negative/neutral/autre\n",
    " if cat not in autre_cats and cat not in neutral_cats:\n",
    " positive_cats.append(cat)\n",
    "\n",
    "print(f\" POSITIVE CATEGORIES ({len(positive_cats)}):\")\n",
    "for i, cat in enumerate(positive_cats, ):\n",
    " # Show first 60 chars of label\n",
    " display_text = cat[:60] + \"...\" if len(cat) > 60 else cat\n",
    " print(f\" {i}. {display_text}\")\n",
    "\n",
    "print(f\"\\n NEGATIVE CATEGORIES ({len(negative_cats)}):\")\n",
    "for i, cat in enumerate(negative_cats, ):\n",
    " display_text = cat[:60] + \"...\" if len(cat) > 60 else cat\n",
    " print(f\" {i}. {display_text}\")\n",
    "\n",
    "print(f\"\\n NEUTRAL CATEGORIES ({len(neutral_cats)}):\")\n",
    "for i, cat in enumerate(neutral_cats, ):\n",
    " display_text = cat[:60] + \"...\" if len(cat) > 60 else cat\n",
    " print(f\" {i}. {display_text}\")\n",
    "\n",
    "print(f\"\\n FALLBACK CATEGORIES ({len(autre_cats)}):\")\n",
    "for i, cat in enumerate(autre_cats, ):\n",
    " print(f\" {i}. {cat}\")\n",
    "\n",
    "print(f\"\\n Note: Categories now include descriptions (from Scripts folder)\")\n",
    "print(f\" Example: 'Accueil chaleureux... (expérience humaine positive...)'\")\n",
    "print(f\" This improves OpenAI classification accuracy with few-shot learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test : Classify Single Review\n",
    "\n",
    "**What this does:** Classifies ONE review to show how the API works\n",
    "\n",
    "**Use case:** Understanding the classification process\n",
    "\n",
    "**Expected output:** Categories detected, sentiment, confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier\n",
    "classifier = ReviewClassifier(debug=True)\n",
    "\n",
    "print(\" ReviewClassifier initialized successfully!\")\n",
    "print(f\" Debug mode: {classifier.debug}\")\n",
    "print(f\" OpenAI client ready: {classifier.client is not None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample review\n",
    "sample_review = \"\"\"\n",
    "Excellent service! Le personnel est très chaleureux et professionnel. \n",
    "L'agence est propre et bien organisée. J'ai été servi rapidement sans attente.\n",
    "Je recommande vivement cette banque.\n",
    "\"\"\"\n",
    "sample_rating = \n",
    "\n",
    "print(f\" TEST: Single Review Classification\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"\\nReview text:\")\n",
    "print(f\"{sample_review.strip()}\")\n",
    "print(f\"Rating: {sample_rating} \")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Classifying with few-shot examples + threshold filtering...\\n\")\n",
    "\n",
    "# Classify (returns dict with sentiment, categories, language, rationale)\n",
    "result = classifier.classify_review(sample_review, sample_rating)\n",
    "\n",
    "if result:\n",
    " print(f\"\\n CLASSIFICATION RESULT\")\n",
    " print(f\"=\"*80)\n",
    " print(f\"\\nOverall sentiment: {result.get('sentiment', 'N/A').upper()}\")\n",
    " print(f\"Language detected: {result.get('language', 'N/A')}\")\n",
    " print(f\"Rationale: {result.get('rationale', 'N/A')}\")\n",
    " \n",
    " if 'categories' in result:\n",
    " categories = result['categories']\n",
    " print(f\"\\nCategories detected: {len(categories)}\")\n",
    " print(f\"(Filtered by confidence >= {config.CONF_THRESHOLD})\\n\")\n",
    " \n",
    " for cat_dict in categories:\n",
    " cat_label = cat_dict.get('label', 'Unknown')\n",
    " confidence = cat_dict.get('confidence', 0)\n",
    " \n",
    " # Visual indicator based on category name\n",
    " if any(neg in cat_label.lower() for neg in ['attente', 'lenteur', 'injoignable', 'réclamation', 'incident', 'frais', 'insatisfaction', 'manque']):\n",
    " icon = ''\n",
    " elif 'hors-sujet' in cat_label.lower():\n",
    " icon = ''\n",
    " elif 'autre' in cat_label.lower():\n",
    " icon = ''\n",
    " else:\n",
    " icon = ''\n",
    " \n",
    " # Show confidence bar\n",
    " bar = '' * int(confidence * 0)\n",
    " # Truncate label for display\n",
    " display_label = cat_label[:0] + \"...\" if len(cat_label) > 0 else cat_label\n",
    " print(f\" {icon} {display_label:} {bar} {confidence:.f}\")\n",
    " else:\n",
    " print(\"\\n No categories detected (or all below threshold)\")\n",
    " print(f\" This triggers fallback to 'Autre ({result.get('sentiment', 'N/A')})'\")\n",
    "else:\n",
    " print(\" Classification failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Scripts folder logic - edge case\n",
    "print(f\" TEST: Edge Case (Generic Negative)\")\n",
    "print(f\"=\"*80)\n",
    "\n",
    "test_review = \"Service nul, madame est arrogante et j'ai attendu h\"\n",
    "test_rating = \n",
    "\n",
    "print(f\"\\nReview: '{test_review}'\")\n",
    "print(f\"Rating: {test_rating} \")\n",
    "print(f\"\\nExpected behavior:\")\n",
    "print(f\" - Few-shot examples help identify specific issues\")\n",
    "print(f\" - Threshold filtering removes low-confidence categories\")\n",
    "print(f\" - Fallback assigns 'Autre (négatif)' if nothing passes threshold\\n\")\n",
    "\n",
    "result = classifier.classify_review(test_review, test_rating)\n",
    "\n",
    "if result:\n",
    " print(f\" RESULT:\")\n",
    " print(f\" Sentiment: {result.get('sentiment', 'N/A')}\")\n",
    " print(f\" Language: {result.get('language', 'N/A')}\")\n",
    " print(f\" Rationale: {result.get('rationale', 'N/A')}\")\n",
    " print(f\"\\n Categories ({len(result.get('categories', []))}):\")\n",
    " \n",
    " for cat_dict in result.get('categories', []):\n",
    " label = cat_dict.get('label', 'Unknown')\n",
    " conf = cat_dict.get('confidence', 0)\n",
    " # Truncate for display\n",
    " display_label = label[:0] + \"...\" if len(label) > 0 else label\n",
    " bar = '' * int(conf * 0)\n",
    " print(f\" • {display_label:} {bar} {conf:.f}\")\n",
    " \n",
    " print(f\"\\n This demonstrates the Scripts folder logic:\")\n",
    " print(f\" Enhanced prompt with detailed rules\")\n",
    " print(f\" Few-shot examples improve accuracy\")\n",
    " print(f\" Threshold filtering prevents low-confidence predictions\")\n",
    " print(f\" Fallback ensures every review gets classified\")\n",
    "else:\n",
    " print(\" Classification failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test : Classify Multiple Sample Reviews\n",
    "\n",
    "**What this does:** Classifies - sample reviews to see variation\n",
    "\n",
    "**Purpose:** Understanding different review types and classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample reviews with different sentiments\n",
    "sample_reviews = [\n",
    " {\n",
    " 'id': ,\n",
    " 'text': \"Service rapide et efficace. Personnel très accueillant.\",\n",
    " 'rating': \n",
    " },\n",
    " {\n",
    " 'id': ,\n",
    " 'text': \"Attente trop longue. Le personnel manque de professionnalisme.\",\n",
    " 'rating': \n",
    " },\n",
    " {\n",
    " 'id': ,\n",
    " 'text': \"Banque classique, rien de spécial. Services standards.\",\n",
    " 'rating': \n",
    " }\n",
    "]\n",
    "\n",
    "print(f\" TEST: Multiple Sample Reviews\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"Classifying {len(sample_reviews)} reviews...\\n\")\n",
    "\n",
    "results = []\n",
    "for review in sample_reviews:\n",
    " print(f\"\\nReview {review['id']} ({review['rating']} ):\")\n",
    " print(f\" Text: {review['text']}\")\n",
    " \n",
    " result = classifier.classify_review(review['text'], review['rating'])\n",
    " \n",
    " if result:\n",
    " sentiment = result.get('sentiment', 'unknown')\n",
    " n_categories = len(result.get('categories', []))\n",
    " print(f\" Sentiment: {sentiment.upper()}, Categories: {n_categories}\")\n",
    " results.append({**review, 'classification': result})\n",
    " else:\n",
    " print(f\" Classification failed\")\n",
    "\n",
    "print(f\"\\n Classified {len(results)}/{len(sample_reviews)} reviews successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test : Batch Classification (Small File)\n",
    "\n",
    "**What this does:** Classifies reviews from CSV file (0-0 reviews)\n",
    "\n",
    "**Use case:** Testing batch processing before full run\n",
    "\n",
    "**Expected output:** CSV with original columns + classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reviews from previous steps (transform or collection)\n",
    "# Priority: transformed data > collected data > legacy path\n",
    "input_file = None\n",
    "\n",
    "# Option : Load from transform step (preferred - normalized data)\n",
    "transform_parquet = project_root / \"data\" / \"0_interim\" / \"transform\" / \"reviews_normalized.parquet\"\n",
    "transform_csv = project_root / \"data\" / \"0_interim\" / \"transform\" / \"reviews_normalized.csv\"\n",
    "\n",
    "# Option : Load from collection step (if transform was skipped)\n",
    "collection_parquet = project_root / \"data\" / \"0_interim\" / \"collection\" / \"reviews.parquet\"\n",
    "collection_csv = project_root / \"data\" / \"0_interim\" / \"collection\" / \"reviews.csv\"\n",
    "\n",
    "# Option : Legacy path\n",
    "legacy_file = project_root / \"data\" / \"output\" / \"reviews_for_classification.csv\"\n",
    "\n",
    "# Try in order of preference\n",
    "for candidate in [transform_parquet, transform_csv, collection_parquet, collection_csv, legacy_file]:\n",
    " if candidate.exists():\n",
    " input_file = candidate\n",
    " break\n",
    "\n",
    "if input_file and input_file.exists():\n",
    " # Load based on file type\n",
    " if input_file.suffix == '.parquet':\n",
    " reviews_df = pd.read_parquet(input_file)\n",
    " else:\n",
    " reviews_df = pd.read_csv(input_file)\n",
    " \n",
    " # Detect column names (new vs old format)\n",
    " text_col = \"text\" if \"text\" in reviews_df.columns else \"review_snippet\" if \"review_snippet\" in reviews_df.columns else None\n",
    " rating_col = \"rating\" if \"rating\" in reviews_df.columns else \"review_rating\" if \"review_rating\" in reviews_df.columns else None\n",
    " business_col = \"_business\" if \"_business\" in reviews_df.columns else \"_bank\" if \"_bank\" in reviews_df.columns else None\n",
    " \n",
    " # Take small sample for testing\n",
    " test_df = reviews_df.head(0).copy()\n",
    " test_input = project_root / \"data\" / \"0_interim\" / \"classification\" / \"test_classify_small.csv\"\n",
    " test_input.parent.mkdir(parents=True, exist_ok=True)\n",
    " test_df.to_csv(test_input, index=False)\n",
    " \n",
    " print(f\" INPUT DATA LOADED\")\n",
    " print(f\"=\"*80)\n",
    " print(f\" Source: {input_file.relative_to(project_root)}\")\n",
    " print(f\" Total reviews available: {len(reviews_df)}\")\n",
    " print(f\" Test sample size: {len(test_df)}\")\n",
    " print(f\" Columns: {list(test_df.columns)}\")\n",
    " \n",
    " # Show detected format\n",
    " print(f\"\\n Detected format:\")\n",
    " if text_col:\n",
    " print(f\" Review text column: '{text_col}'\")\n",
    " if rating_col:\n",
    " print(f\" Rating column: '{rating_col}'\")\n",
    " if business_col:\n",
    " print(f\" Business column: '{business_col}'\")\n",
    " \n",
    " # Check if data has been transformed\n",
    " if 'created_at' in reviews_df.columns or 'region' in reviews_df.columns:\n",
    " print(f\"\\n Transformed data detected!\")\n",
    " if 'created_at' in reviews_df.columns:\n",
    " print(f\" Normalized dates\")\n",
    " if 'region' in reviews_df.columns:\n",
    " print(f\" Regions added\")\n",
    " region_count = reviews_df['region'].notna().sum()\n",
    " print(f\" {region_count}/{len(reviews_df)} reviews have region data\")\n",
    " \n",
    " # Show sample (handle both formats)\n",
    " print(f\"\\n Sample reviews:\")\n",
    " display_cols = []\n",
    " if text_col:\n",
    " display_cols.append(text_col)\n",
    " if rating_col:\n",
    " display_cols.append(rating_col)\n",
    " if business_col and business_col in test_df.columns:\n",
    " display_cols.insert(0, business_col)\n",
    " if display_cols:\n",
    " display(test_df[display_cols].head())\n",
    " else:\n",
    " display(test_df.head())\n",
    " \n",
    "else:\n",
    " print(f\" No reviews file found!\")\n",
    " print(f\"\\n Tried locations:\")\n",
    " print(f\" . {transform_parquet.relative_to(project_root)} (preferred)\")\n",
    " print(f\" . {collection_parquet.relative_to(project_root)}\")\n",
    " print(f\" . {legacy_file.relative_to(project_root)} (legacy)\")\n",
    " print(f\"\\n Please run collect_reviews.ipynb first, or run the transform step:\")\n",
    " print(f\" python -m review_analyzer.main transform\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch classification\n",
    "output_path = project_root / \"data\" / \"0_processed\" / \"classification\" / f\"test_classified_small_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\" BATCH CLASSIFICATION\")\n",
    "print(f\"=\"*80)\n",
    "print(f\" Input: {test_input.relative_to(project_root)}\")\n",
    "print(f\" Output: {output_path.relative_to(project_root)}\")\n",
    "print(f\"\\n Classifying {len(test_df)} reviews...\")\n",
    "print(f\" Note: Column names auto-detected\\n\")\n",
    "\n",
    "# Read the test data\n",
    "df_to_classify = pd.read_csv(test_input)\n",
    "\n",
    "# Classify (auto-detects 'text'/'review_snippet' and 'rating'/'review_rating')\n",
    "classified_df = classifier.classify_batch(df_to_classify)\n",
    "\n",
    "# Save results\n",
    "classified_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" CLASSIFICATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\" Reviews processed: {len(classified_df)}\")\n",
    "print(f\" Output saved: {output_path.relative_to(project_root)}\")\n",
    "print(f\" New columns added: sentiment, categories_json, language, rationale\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect classified results\n",
    "if output_path.exists():\n",
    " classified_df = pd.read_csv(output_path)\n",
    " \n",
    " print(f\"\\n CLASSIFIED RESULTS\")\n",
    " print(f\"=\"*80)\n",
    " print(f\" Total rows: {len(classified_df)}\")\n",
    " print(f\" Columns: {list(classified_df.columns)}\\n\")\n",
    " \n",
    " # Detect columns\n",
    " text_col = \"text\" if \"text\" in classified_df.columns else \"review_snippet\"\n",
    " rating_col = \"rating\" if \"rating\" in classified_df.columns else \"review_rating\"\n",
    " \n",
    " # Show sample\n",
    " print(\"Sample classified reviews:\")\n",
    " display_cols = [text_col, rating_col, 'sentiment', 'language']\n",
    " display(classified_df[display_cols].head())\n",
    " \n",
    " # Sentiment distribution\n",
    " if 'sentiment' in classified_df.columns:\n",
    " print(f\"\\n Sentiment Distribution:\")\n",
    " sentiment_counts = classified_df['sentiment'].value_counts()\n",
    " for sentiment, count in sentiment_counts.items():\n",
    " percentage = (count / len(classified_df)) * 00\n",
    " bar = '' * int(percentage / )\n",
    " print(f\" {sentiment:0} {count:} {bar} {percentage:.f}%\")\n",
    " \n",
    " # Top categories (parse categories_json)\n",
    " if 'categories_json' in classified_df.columns:\n",
    " print(f\"\\n Top Categories Detected:\")\n",
    " all_categories = []\n",
    " for cats_json in classified_df['categories_json'].dropna():\n",
    " try:\n",
    " cats_list = json.loads(cats_json) if isinstance(cats_json, str) else cats_json\n",
    " for cat_dict in cats_list:\n",
    " all_categories.append(cat_dict.get('label', 'Unknown'))\n",
    " except:\n",
    " pass\n",
    " \n",
    " if all_categories:\n",
    " from collections import Counter\n",
    " cat_counts = Counter(all_categories).most_common(0)\n",
    " for cat, count in cat_counts:\n",
    " print(f\" {cat[:0]:} {count:} occurrences\")\n",
    "else:\n",
    " print(f\" Output file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test : Wide Format Classification\n",
    "\n",
    "**What this does:** Classifies reviews and creates 7 binary category columns\n",
    "\n",
    "**Use case:** Analysis-ready format for statistical modeling\n",
    "\n",
    "**Expected output:** CSV with columns like cat_service, cat_competence, etc. (0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify in wide format\n",
    "output_path_wide = project_root / \"data\" / \"0_processed\" / \"classification\" / f\"test_classified_wide_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "output_path_wide.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\" WIDE FORMAT CLASSIFICATION\")\n",
    "print(f\"=\"*80)\n",
    "print(f\" This creates binary category columns (0/)\")\n",
    "print(f\" Perfect for statistical analysis and modeling\\n\")\n",
    "\n",
    "# Read test data and classify\n",
    "df_to_classify_wide = pd.read_csv(test_input)\n",
    "classified_df_wide = classifier.classify_batch(df_to_classify_wide)\n",
    "\n",
    "# Convert to wide format\n",
    "wide_df = classifier.convert_to_wide_format(classified_df_wide)\n",
    "\n",
    "# Save\n",
    "wide_df.to_csv(output_path_wide, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" CLASSIFICATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\" Reviews processed: {len(wide_df)}\")\n",
    "print(f\" Output saved: {output_path_wide.relative_to(project_root)}\")\n",
    "print(f\" Format: Wide format with binary category columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect wide format results\n",
    "if output_path_wide.exists():\n",
    " wide_df = pd.read_csv(output_path_wide)\n",
    " \n",
    " # Detect columns\n",
    " text_col = \"text\" if \"text\" in wide_df.columns else \"review_snippet\"\n",
    " rating_col = \"rating\" if \"rating\" in wide_df.columns else \"review_rating\"\n",
    " \n",
    " print(f\"\\n WIDE FORMAT RESULTS\")\n",
    " print(f\"=\"*80)\n",
    " print(f\" Total rows: {len(wide_df)}\")\n",
    " print(f\" Total columns: {len(wide_df.columns)}\\n\")\n",
    " \n",
    " # Find category columns (they match CATEGORIES list from config)\n",
    " cat_cols = [col for col in wide_df.columns if col in config.CATEGORIES]\n",
    " \n",
    " # Show all columns\n",
    " print(f\"Column overview:\")\n",
    " print(f\" Original columns: {text_col}, {rating_col}, sentiment, language, etc.\")\n",
    " print(f\" Category columns ({len(cat_cols)}): binary 0/ flags\\n\")\n",
    " \n",
    " # Show top categories by frequency\n",
    " if cat_cols:\n",
    " cat_sums = wide_df[cat_cols].sum().sort_values(ascending=False)\n",
    " \n",
    " print(f\" Top 0 Most Frequent Categories:\")\n",
    " for i, (cat, count) in enumerate(cat_sums.head(0).items(), ):\n",
    " percentage = (count / len(wide_df)) * 00\n",
    " bar = '' * int(percentage / )\n",
    " print(f\" {i:}. {cat[:0]:} {int(count):} {bar} {percentage:.f}%\")\n",
    " \n",
    " # Show sample rows\n",
    " print(f\"\\n Sample rows (first category columns):\")\n",
    " sample_cat_cols = cat_sums.head().index.tolist()\n",
    " display(wide_df[[text_col, rating_col, 'sentiment'] + sample_cat_cols].head())\n",
    " else:\n",
    " print(\" No category columns found\")\n",
    "else:\n",
    " print(f\" Output file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6: Visualize Classification Results\n",
    "\n",
    "**What this does:** Creates visualizations of classified data\n",
    "\n",
    "**Outputs:**\n",
    "- Sentiment distribution pie chart\n",
    "- Category frequency bar chart\n",
    "- Rating vs Sentiment heatmap\n",
    "- Category co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wide format for visualization\n",
    "if output_path_wide.exists():\n",
    " wide_df = pd.read_csv(output_path_wide)\n",
    " \n",
    " # Detect columns\n",
    " rating_col = \"rating\" if \"rating\" in wide_df.columns else \"review_rating\"\n",
    " \n",
    " print(f\" CLASSIFICATION VISUALIZATIONS\")\n",
    " print(f\"=\"*80)\n",
    " print(f\"Total reviews: {len(wide_df)}\\n\")\n",
    " \n",
    " # Find category columns\n",
    " cat_cols = [col for col in wide_df.columns if col in config.CATEGORIES]\n",
    " \n",
    " # Set style\n",
    " plt.style.use('seaborn-v0_8-whitegrid')\n",
    " \n",
    " # . Sentiment distribution\n",
    " if 'sentiment' in wide_df.columns:\n",
    " fig, ax = plt.subplots(figsize=(8, 8))\n",
    " sentiment_counts = wide_df['sentiment'].value_counts()\n",
    " colors = ['#ecc7', '#e7cc', '#9aa6'] # Green, red, gray\n",
    " ax.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%.f%%',\n",
    " colors=colors, startangle=90)\n",
    " ax.set_title('Sentiment Distribution', fontsize=, fontweight='bold')\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " # . Top 0 categories\n",
    " if cat_cols:\n",
    " cat_sums = wide_df[cat_cols].sum().sort_values(ascending=True).tail(0)\n",
    " \n",
    " fig, ax = plt.subplots(figsize=(, 6))\n",
    " cat_sums.plot(kind='barh', ax=ax, color='steelblue')\n",
    " ax.set_title('Top 0 Most Frequent Categories', fontsize=, fontweight='bold')\n",
    " ax.set_xlabel('Number of Reviews', fontsize=)\n",
    " ax.set_ylabel('Category', fontsize=)\n",
    " ax.grid(axis='x', alpha=0.)\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " # . Rating vs Sentiment\n",
    " if rating_col in wide_df.columns and 'sentiment' in wide_df.columns:\n",
    " crosstab = pd.crosstab(wide_df[rating_col], wide_df['sentiment'])\n",
    " \n",
    " fig, ax = plt.subplots(figsize=(0, 6))\n",
    " sns.heatmap(crosstab, annot=True, fmt='d', cmap='YlOrRd', ax=ax)\n",
    " ax.set_title('Rating vs Sentiment Analysis', fontsize=, fontweight='bold')\n",
    " ax.set_xlabel('Sentiment', fontsize=)\n",
    " ax.set_ylabel('Rating (Stars)', fontsize=)\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " # . Category co-occurrence (top 8 categories)\n",
    " if cat_cols and len(cat_cols) >= 8:\n",
    " top_8_cats = wide_df[cat_cols].sum().sort_values(ascending=False).head(8).index\n",
    " corr_matrix = wide_df[top_8_cats].corr()\n",
    " \n",
    " fig, ax = plt.subplots(figsize=(0, 8))\n",
    " sns.heatmap(corr_matrix, annot=True, fmt='.f', cmap='coolwarm', \n",
    " center=0, ax=ax, square=True)\n",
    " ax.set_title('Category Co-occurrence Matrix (Top 8)', fontsize=, fontweight='bold')\n",
    " plt.tight_layout()\n",
    " plt.show()\n",
    " \n",
    " print(\"\\n Interpretation:\")\n",
    " print(\" Positive values (red) = categories often appear together\")\n",
    " print(\" Negative values (blue) = categories rarely appear together\")\n",
    " print(\" Values close to 0 (white) = no correlation\")\n",
    "else:\n",
    " print(\" No classified data found. Run Test first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 7: Confidence Threshold Impact\n",
    "\n",
    "**What this does:** Shows how confidence threshold affects classification\n",
    "\n",
    "**Purpose:** Understanding the trade-off between precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze confidence threshold impact\n",
    "thresholds = [0., 0., 0., 0., 0.6, 0.7, 0.8]\n",
    "\n",
    "print(f\" CONFIDENCE THRESHOLD IMPACT\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"Current threshold: {config.CONF_THRESHOLD}\")\n",
    "print(f\"\\nHigher threshold Fewer but more confident predictions\")\n",
    "print(f\"Lower threshold More predictions but less confident\\n\")\n",
    "\n",
    "if output_path_wide.exists():\n",
    " wide_df = pd.read_csv(output_path_wide)\n",
    " \n",
    " # Find category columns (match CATEGORIES list)\n",
    " cat_cols = [col for col in wide_df.columns if col in config.CATEGORIES]\n",
    " \n",
    " if cat_cols:\n",
    " current_categories = wide_df[cat_cols].sum().sum()\n",
    " avg_per_review = current_categories / len(wide_df)\n",
    " \n",
    " print(f\"With current threshold ({config.CONF_THRESHOLD}):\")\n",
    " print(f\" Total category assignments: {int(current_categories)}\")\n",
    " print(f\" Average categories per review: {avg_per_review:.f}\")\n",
    " print(f\" Reviews with at least category: {(wide_df[cat_cols].sum(axis=) > 0).sum()}\")\n",
    " \n",
    " # Estimate impact of different thresholds\n",
    " print(f\"\\n Estimated impact of different thresholds:\")\n",
    " for threshold in thresholds:\n",
    " # Rough estimation based on normal distribution\n",
    " factor = - (threshold - config.CONF_THRESHOLD) * 0.\n",
    " estimated_cats = int(current_categories * max(0., factor))\n",
    " bar = '' * int(factor * 0)\n",
    " \n",
    " marker = ' CURRENT' if abs(threshold - config.CONF_THRESHOLD) < 0.0 else ''\n",
    " print(f\" {threshold:.f}: ~{estimated_cats:} total categories {bar} {marker}\")\n",
    " \n",
    " print(f\"\\n Recommendation:\")\n",
    " print(f\" - Use {config.CONF_THRESHOLD} (current) for balanced results\")\n",
    " print(f\" - Use 0.70+ for high-confidence predictions only\")\n",
    " print(f\" - Use 0.0- for exploratory analysis\")\n",
    " \n",
    " print(f\"\\n Fallback mechanism:\")\n",
    " print(f\" - If no categories pass threshold assigns 'Autre (positif/négatif)'\")\n",
    " print(f\" - Ensures every review gets at least one classification\")\n",
    " print(f\" - Based on overall sentiment from OpenAI\")\n",
    " else:\n",
    " print(\" No category columns found\")\n",
    "else:\n",
    " print(\" No data available. Run Test first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Final Results\n",
    "\n",
    "**What this does:** Prepares classified data for analysis\n",
    "\n",
    "**Outputs:**\n",
    "- CSV with wide format (ready for analysis)\n",
    "- Summary statistics\n",
    "- Export confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final results\n",
    "if output_path_wide.exists():\n",
    " wide_df = pd.read_csv(output_path_wide)\n",
    " \n",
    " # Detect columns\n",
    " rating_col = \"rating\" if \"rating\" in wide_df.columns else \"review_rating\" if \"review_rating\" in wide_df.columns else None\n",
    " business_col = \"_business\" if \"_business\" in wide_df.columns else \"_bank\" if \"_bank\" in wide_df.columns else None\n",
    " \n",
    " # Save to new data architecture\n",
    " final_export = project_root / \"data\" / \"0_processed\" / \"classification\" / \"reviews_classified_final.csv\"\n",
    " final_export.parent.mkdir(parents=True, exist_ok=True)\n",
    " wide_df.to_csv(final_export, index=False)\n",
    " \n",
    " # Also save to legacy path for backward compatibility\n",
    " legacy_export = project_root / \"data\" / \"output\" / \"reviews_classified_final.csv\"\n",
    " legacy_export.parent.mkdir(parents=True, exist_ok=True)\n",
    " wide_df.to_csv(legacy_export, index=False)\n",
    " \n",
    " print(f\" EXPORT COMPLETE\")\n",
    " print(f\"=\"*80)\n",
    " print(f\" Primary: {final_export.relative_to(project_root)}\")\n",
    " print(f\" Legacy: {legacy_export.relative_to(project_root)}\")\n",
    " print(f\" Records: {len(wide_df)}\")\n",
    " print(f\" Columns: {len(wide_df.columns)}\")\n",
    " \n",
    " # Category columns\n",
    " cat_cols = [col for col in wide_df.columns if col in config.CATEGORIES]\n",
    " print(f\" Category columns: {len(cat_cols)}\")\n",
    " \n",
    " # Summary stats\n",
    " print(f\"\\n SUMMARY STATISTICS:\")\n",
    " if 'sentiment' in wide_df.columns:\n",
    " sentiment_dist = wide_df['sentiment'].value_counts()\n",
    " print(f\"\\n Sentiment:\")\n",
    " for sent, count in sentiment_dist.items():\n",
    " print(f\" {sent}: {count} ({count/len(wide_df)*00:.f}%)\")\n",
    " \n",
    " if rating_col and rating_col in wide_df.columns:\n",
    " print(f\"\\n Rating:\")\n",
    " print(f\" Average: {wide_df[rating_col].mean():.f} \")\n",
    " print(f\" Median: {wide_df[rating_col].median():.f} \")\n",
    " \n",
    " if cat_cols:\n",
    " total_assignments = wide_df[cat_cols].sum().sum()\n",
    " avg_per_review = total_assignments / len(wide_df)\n",
    " print(f\"\\n Categories:\")\n",
    " print(f\" Total assignments: {int(total_assignments)}\")\n",
    " print(f\" Average per review: {avg_per_review:.f}\")\n",
    " print(f\" Reviews with categories: {(wide_df[cat_cols].sum(axis=) > 0).sum()}\")\n",
    " \n",
    " # Show business breakdown if available\n",
    " if business_col and business_col in wide_df.columns:\n",
    " business_counts = wide_df[business_col].value_counts()\n",
    " print(f\"\\n Reviews by business/location:\")\n",
    " for business, count in business_counts.head().items():\n",
    " print(f\" - {business}: {count}\")\n",
    " if len(business_counts) > :\n",
    " print(f\" ... and {len(business_counts) - } more\")\n",
    " \n",
    " # Show region breakdown if available\n",
    " if 'region' in wide_df.columns:\n",
    " region_counts = wide_df['region'].value_counts()\n",
    " print(f\"\\n Reviews by region:\")\n",
    " for region, count in region_counts.head().items():\n",
    " print(f\" - {region}: {count}\")\n",
    " if len(region_counts) > :\n",
    " print(f\" ... and {len(region_counts) - } more\")\n",
    " \n",
    " print(f\"\\n Data saved to: data/0_processed/classification/\")\n",
    " print(f\"\\n Ready for analysis! \")\n",
    " print(f\" You can now:\")\n",
    " print(f\" • Open in Excel for pivot tables\")\n",
    " print(f\" • Load in Python/R for statistical analysis\")\n",
    " print(f\" • Create dashboards with Power BI/Tableau\")\n",
    " print(f\" • Build aggregates by region, city, or business\")\n",
    "else:\n",
    " print(\" No classified data found. Run Test first!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary for New Developers\n",
    "\n",
    "**What you learned:**\n",
    "\n",
    ". **ReviewClassifier** - AI-powered review classification using OpenAI GPT-\n",
    ". **Flexible Input Format** - Auto-detects column names from both new and old formats:\n",
    " - New: `text`, `rating`, `_place_id`, `_city`, `_business`\n",
    " - Old: `review_snippet`, `review_rating`, `_bank`\n",
    ". **Scripts Folder Logic Integration** - The classifier now uses proven logic from Scripts:\n",
    " - Enhanced system prompt with detailed rules and abstention policy\n",
    " - Few-shot learning ( representative examples included in every API call)\n",
    " - Threshold filtering at {config.CONF_THRESHOLD} confidence\n",
    " - Fallback mechanism: assigns \"Autre (positif/négatif)\" when no categories pass threshold\n",
    " - Temperature=0 for deterministic, reproducible results\n",
    " - Robust message extraction ( fallback methods for OpenAI responses)\n",
    ". **Classification Categories** - 7 categories with embedded descriptions\n",
    ". **Output formats:**\n",
    " - Long format: nested JSON with categories (categories_json column)\n",
    " - Wide format: binary columns (0/) for each category - perfect for analysis\n",
    "6. **Sentiment analysis** - Overall Positif/Négatif/Neutre classification\n",
    "7. **Multi-language support** - Handles French, English, Arabic/Darija, emojis\n",
    "8. **New data architecture** - Organized folder structure for better data management\n",
    "\n",
    "**Key takeaways:**\n",
    "- Column names are auto-detected - no manual specification needed\n",
    "- Test with single reviews first using `classify_review(text, rating)`\n",
    "- Use `classify_batch(df)` for DataFrames - auto-detects columns\n",
    "- Use wide format for statistical analysis (`convert_to_wide_format()`)\n",
    "- Confidence threshold balances precision vs recall\n",
    "- Fallback ensures every review gets classified (no empty results)\n",
    "- Few-shot examples improve accuracy on edge cases\n",
    "- Checkpoint system prevents data loss during long runs (built into classify_batch)\n",
    "- Data flows through organized pipeline stages\n",
    "\n",
    "**Understanding the results:**\n",
    "- **sentiment**: Overall feeling (Positif/Négatif/Neutre)\n",
    "- **categories_json**: List of detected categories with confidence scores (filtered by threshold)\n",
    "- **language**: Detected language of the review\n",
    "- **rationale**: Brief explanation of the classification\n",
    "- Wide format: Each category becomes a binary column ( if detected, 0 if not)\n",
    "\n",
    "**Scripts Folder Logic (Now Integrated):**\n",
    "- Enhanced prompt with RÈGLES DE CLASSIFICATION and POLITIQUE D'ABSTENTION\n",
    "- Few-shot examples ( samples covering mixed, digital, generic, off-topic cases)\n",
    "- Threshold filtering removes low-confidence predictions\n",
    "- Fallback mechanism assigns \"Autre (±)\" based on sentiment\n",
    "- Message extraction with fallback methods for robustness\n",
    "- Temperature=0 for deterministic output\n",
    "- CATEGORIES and CONF_THRESHOLD naming convention\n",
    "\n",
    "**Data Flow (New Architecture):**\n",
    "```\n",
    "discover collect transform classify\n",
    " ↓ ↓ ↓ ↓\n",
    "0_raw/ 0_interim/ 0_interim/ 0_processed/\n",
    "discovery collection transform classification\n",
    "```\n",
    "\n",
    "**This notebook processes:**\n",
    "- **Input**: `data/0_interim/transform/reviews_normalized.parquet` (after transform)\n",
    " - Or: `data/0_interim/collection/reviews.csv` (if transform skipped)\n",
    "- **Output**: `data/0_processed/classification/reviews_classified_final.csv`\n",
    "\n",
    "**Backward Compatibility:**\n",
    "- Works with old collection format (review_snippet, review_rating, _bank)\n",
    "- Works with new collection format (text, rating, _business)\n",
    "- Works with transformed data (includes region, created_at, normalized fields)\n",
    "- Seamlessly integrates with enhanced discovery (canonical place IDs, OSM data)\n",
    "- Old config names still work (REVIEW_CATEGORIES, CONFIDENCE_THRESHOLD)\n",
    "\n",
    "**Next steps:**\n",
    ". You've discovered place_ids (Step : discover_placeids.ipynb)\n",
    ". You've collected reviews (Step : collect_reviews.ipynb)\n",
    ". Transform reviews - normalize fields, add regions (Optional but recommended)\n",
    ". You've classified reviews (Step : classify_reviews.ipynb - this notebook!)\n",
    ". Next: Analyze results, create reports, build dashboards!\n",
    "\n",
    "**For production runs:**\n",
    "- Use `classify_batch(df)` for automatic column detection\n",
    "- Convert to wide format with `convert_to_wide_format(df)` for analysis\n",
    "- Monitor API usage and costs (temperature=0 helps with consistency)\n",
    "- Validate results with sample reviews\n",
    "- Trust the fallback mechanism - it prevents empty classifications\n",
    "\n",
    "**Pipeline Command (Run all steps):**\n",
    "```bash\n",
    "python -m review_analyzer.main pipeline \\\n",
    " --businesses \"Attijariwafa Bank\" \\\n",
    " --cities \"Casablanca\" \\\n",
    " --business-type \"bank\"\n",
    "```\n",
    "\n",
    "**Troubleshooting:**\n",
    "- API errors? Check .env file has OPENAI_API_KEY set\n",
    "- No categories? Check threshold - might be too high. Fallback should assign \"Autre (±)\"\n",
    "- High API costs? Reduce number of reviews or batch size\n",
    "- Column not found errors? Check your input CSV has either text/review_snippet and rating/review_rating columns\n",
    "- Inconsistent results? Temperature is set to 0 for reproducibility - same input = same output\n",
    "\n",
    "Happy classifying! \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}