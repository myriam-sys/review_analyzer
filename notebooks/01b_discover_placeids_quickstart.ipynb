{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place Discovery Quickstart\n",
    "\n",
    "Purpose: Find canonical Google Maps place IDs (ChIJ...) for selected businesses and cities in Morocco.\n",
    "\n",
    "What you will do:\n",
    "- Ensure city map centers and aliases are available (built from OSM once).\n",
    "- Run discovery for a small list of businesses and cities.\n",
    "- Validate canonical IDs and export a clean CSV for the next step (review collection).\n",
    "\n",
    "Requirements:\n",
    "- SERPAPI_API_KEY in your environment (.env or export).\n",
    "- Internet access for SerpAPI.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: import from src and verify OSM-derived centers\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "from review_analyzer.geo import ensure_osm_derived_files, resolve_city_name\n",
    "from review_analyzer.discover import DiscoveryEngine\n",
    "from review_analyzer import config\n",
    "\n",
    "centers, aliases = ensure_osm_derived_files()\n",
    "print(f\" Centers: {len(centers)} | Aliases: {len(aliases)}\")\n",
    "print(\"Sample:\")\n",
    "for i, (k, v) in enumerate(centers.items()):\n",
    " print(\" \", k, \"->\", v)\n",
    " if i == :\n",
    " break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a small discovery (canonical IDs preferred automatically)\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "engine = DiscoveryEngine(debug=True)\n",
    "\n",
    "businesses = [\"Crédit Agricole\", \"CFG Bank\"]\n",
    "cities = [\"Rabat\", \"Kénitra\"] # accents are OK; aliases resolve automatically\n",
    "output_path = project_root / \"data\" / \"0_processed\" / \"discovery\" / f\"quick_discovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Running discovery...\")\n",
    "df = engine.discover_branches(\n",
    " businesses=businesses,\n",
    " cities=cities,\n",
    " business_type=\"banque\",\n",
    " map_centers=None, # engine loads OSM/default\n",
    " brand_filter=None,\n",
    " output_path=output_path,\n",
    ")\n",
    "print(f\" Done {output_path.relative_to(project_root)}\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate canonical IDs and basic summary\n",
    "import re\n",
    "\n",
    "id_col = (\n",
    " 'canonical_place_id'\n",
    " if ('canonical_place_id' in df.columns and df['canonical_place_id'].notna().any())\n",
    " else 'place_id' if 'place_id' in df.columns else None\n",
    ")\n",
    "print(\"ID column:\", id_col)\n",
    "\n",
    "rx = re.compile(r\"^ChIJ[0-9A-Za-z_-]+$\")\n",
    "non = 0\n",
    "if id_col:\n",
    " non = df[id_col].dropna().astype(str).apply(lambda x: not bool(rx.match(x))).sum()\n",
    "print(\"rows:\", len(df), \"non_canonical:\", non)\n",
    "\n",
    "if id_col and non == 0:\n",
    " print(\"All IDs are canonical (ChIJ…)\")\n",
    "\n",
    "print(\"Businesses:\", sorted(df['business'].dropna().unique().tolist())[:8] if 'business' in df.columns else [])\n",
    "print(\"Cities:\", sorted(df['city'].dropna().unique().tolist())[:8] if 'city' in df.columns else [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for next step (review collection)\n",
    "\n",
    "# Choose best ID per row: canonical_place_id > place_id > data_id (string fallback)\n",
    "import pandas as pd\n",
    "\n",
    "def choose_id(row):\n",
    " cid = row.get('canonical_place_id')\n",
    " if isinstance(cid, str) and config.validate_place_id(cid):\n",
    " return cid\n",
    " pid = row.get('place_id')\n",
    " if isinstance(pid, str) and config.validate_place_id(pid):\n",
    " return pid\n",
    " did = row.get('data_id')\n",
    " if pd.notna(did) and str(did).strip() != \"\":\n",
    " return str(did)\n",
    " return None\n",
    "\n",
    "ids = df.apply(choose_id, axis=)\n",
    "\n",
    "df_out = pd.DataFrame({\n",
    " '_place_id': ids,\n",
    " '_business': df.get('business'),\n",
    " '_city': df.get('city'),\n",
    " 'title': df.get('name'),\n",
    " 'address': df.get('address')\n",
    "}).dropna(subset=['_place_id']).drop_duplicates(subset=['_place_id'])\n",
    "\n",
    "# Save to new data architecture\n",
    "next_step_file = project_root / 'data' / '0_processed' / 'discovery' / 'agencies_discovered.csv'\n",
    "next_step_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(next_step_file, index=False)\n",
    "\n",
    "# Also save to legacy path for backward compatibility\n",
    "legacy_file = project_root / 'data' / 'output' / 'agencies_for_collection.csv'\n",
    "legacy_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(legacy_file, index=False)\n",
    "\n",
    "print(f\"Exported:\")\n",
    "print(f\" Primary: {next_step_file.relative_to(project_root)}\")\n",
    "print(f\" Legacy: {legacy_file.relative_to(project_root)}\")\n",
    "print(f\" Rows: {len(df_out)}\")\n",
    "print(f\"\\nData saved to: data/0_processed/discovery/\")\n",
    "print(f\"\\nNext: Open collect_reviews.ipynb\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
